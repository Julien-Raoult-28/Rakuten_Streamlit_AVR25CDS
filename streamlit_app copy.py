from importlib.resources import path
import streamlit as st
import joblib


st.set_page_config(
    page_title="Rakuten AVR25CDS",   # titre affich√© dans l'onglet du navigateur
    page_icon="images/favicon_Rakuten.png",             # emoji ou chemin vers une ic√¥ne .png
    layout="wide"               # optionnel : wide ou centered
)

st.markdown("""
    <div style="
    position: fixed;   /* fixe le bandeau en haut */
    top: 60px;
    left: 100px;
    width: 100%;       /* s'√©tend sur toute la largeur */
    height: 70px;      /* hauteur du bandeau */
    display: flex;     /* active Flexbox */
    align-items: center; /* centre verticalement */
    justify-content: center; /* centre horizontalement */
    background-color: #efefef; 
    z-index: 1000;      /* pour rester au-dessus des autres √©l√©ments */
">
    <h3 style="color: #bf0000; margin: 0;">
        Classification des donn√©es produits multimodales de Rakuten France
    </h3>
</div>

<!-- Evite que le contenu soit cach√© par le bandeau -->
<div style="margin-top:70px;"></div>
""", unsafe_allow_html=True)

# --- TRAIT SEPARATION ---

st.markdown("""
            ---
  """, unsafe_allow_html=True)

# --------------------- STYLE PERSONNALIS√â POUR LE MENU DE GAUCHE SIDEBAR ---
st.markdown("""
    <style>
    /* Couleur de fond de la sidebar */
    section[data-testid="stSidebar"] {
        background-color: #efefef;   
    }

    /* Couleur du texte dans la sidebar */
    section[data-testid="stSidebar"] * {
        color: #bf0000 !important;    
    }
    </style>
""", unsafe_allow_html=True)




# === LOGO + SOMMAIRE DANS LA SIDEBAR ===
# --- Sidebar ---
with st.sidebar:
    st.image("images/rakuten.png", use_container_width=True)
    st.markdown("<br>", unsafe_allow_html=True)
    st.title("Sommaire")

    pages = ["Pr√©sentation du projet","Exploration", "Pr√©paration", "Mod√©lisation - texte", "Mod√©lisation - image","Tester le mod√®le"]
    page = st.radio("", pages)

    # --- Auteurs ---
    st.markdown("<hr>", unsafe_allow_html=True)
    st.markdown(
        """
        **Auteurs :**  
        Angella FONTAINE  
        Fatiha IDDER  
        Julien RAOULT
        """,
        unsafe_allow_html=True
    )


# --- TITRE DE CHAQUE PAGE ---
def affiche_bandeau(titre, couleur_fond="#bf0000"):
    st.markdown(f"""
        <div style="
            /*background-color: {couleur_fond};*/
            padding: 3px;
            border-radius: 5px;
            text-align: center;
            height:60px;
        ">
            <h3 style="color: #bf0000; margin: 0;">{titre}</h3>
        </div>
        <br>
    """, unsafe_allow_html=True)



# === CONTENU DES PAGES ===
#---------------------------------------PAGE PRESENTATION DU PROJET -----------------------------------------
if page == pages[0] : 
  affiche_bandeau("Pr√©sentation du projet", "#bf0000")
  st.write("""
###  Contexte Rakuten  

Rakuten est un des plus grands acteurs mondiaux du e-commerce, cr√©√© en 1997, 
avec plus de **1,3 milliard d‚Äôutilisateurs** dans son √©cosyst√®me international.
Le **Rakuten Institute of Technology (RIT)** m√®ne des recherches en apprentissage automatique,
vision par ordinateur, NLP et HCI, avec des √©quipes √† Tokyo, Paris, Boston, Singapour et Bengaluru.  
           
### Objectif du projet  
           
Cr√©er un mod√®le capable de **classer automatiquement les produits** du catalogue Rakuten France
dans leur code type produit (prdtypecode), en utilisant du texte (titre, description) et/ou des images.
C‚Äôest un probl√®me de **classification multimodale** √† grande √©chelle.  
           
### Contexte du challenge  

Cat√©goriser les produits est un enjeu crucial pour les marketplaces (recherche, recommandation, compr√©hension des requ√™tes).
Les approches manuelles ou bas√©es sur des r√®gles ne sont pas scalables.
Le d√©fi est difficile √† cause de :  
&nbsp;&nbsp;&nbsp;&nbsp;‚Ä¢ Donn√©es textuelles bruyantes  
&nbsp;&nbsp;&nbsp;&nbsp;‚Ä¢ Images vari√©es et h√©t√©rog√®nes  
&nbsp;&nbsp;&nbsp;&nbsp;‚Ä¢ Grand nombre de classes  
&nbsp;&nbsp;&nbsp;&nbsp;‚Ä¢ Distribution d√©s√©quilibr√©e  
&nbsp;&nbsp;&nbsp;&nbsp;‚Ä¢ Qualit√© in√©gale des informations fournies par les vendeurs  
Le challenge consiste √† exploiter texte + image pour construire un classifieur performant.  
           
### Description du probl√®me  

Pour chaque produit (avec titre, image, parfois description), pr√©dire son prdtypecode.  
Exemple : Klarstein Pr√©sentoir 2 Montres‚Ä¶ ‚Üí cat√©gorie produit 1500.  
Les donn√©es ressemblent √† :  
&nbsp;&nbsp;&nbsp;&nbsp;‚Ä¢ Designation : titre du produit  
&nbsp;&nbsp;&nbsp;&nbsp;‚Ä¢ Description : texte descriptif (souvent manquant)  
&nbsp;&nbsp;&nbsp;&nbsp;‚Ä¢ Productid et imageid : permettent de retrouver l‚Äôimage  
&nbsp;&nbsp;&nbsp;&nbsp;‚Ä¢ Image : une seule image par produit  
&nbsp;&nbsp;&nbsp;&nbsp;‚Ä¢ Prdtypecode : label √† pr√©dire  
           
### Jeu de donn√©es  

Rakuten fournit environ 99 000 produits :  
&nbsp;&nbsp;&nbsp;&nbsp;‚Ä¢ X_train (84 916) : textes + images  
&nbsp;&nbsp;&nbsp;&nbsp;‚Ä¢ Y_train : prdtypecode pour chaque id  
&nbsp;&nbsp;&nbsp;&nbsp;‚Ä¢ X_test (13 812) : textes + images √† pr√©dire  
&nbsp;&nbsp;&nbsp;&nbsp;‚Ä¢ images.zip : dossier contenant toutes les images (train/test s√©par√©es)  
           
### Objectif  
L'objectif est d'obtenir un F1-score sup√©rieur √† **0,8113 sur les donn√©es textuelles**.  
Pour les **images**, l'objectif est d'atteindre un F1-score sup√©rieur √† **0,5534**.
""")
#---------------------------------------PAGE EXPLORATION DE LA DONNEE -----------------------------------------
if page == pages[1] : 
  affiche_bandeau("Exploration des donn√©es", "#bf0000")
  st.write("""
### Exploration de la donn√©e textuelle  

#### üîé Visualisation du dataset  
Structure du dataset X  
""")
  st.image("images/Visualisation_X.png", use_container_width=True)
  st.write("""
Structure du dataset Y  
""")
  st.image("images/Visualisation_Y.png", use_container_width=False)
  st.write("""
#### ‚úÖ Qualit√© de la donn√©e 
Lors de l'exploration du dataset nous identifions plusieurs probl√®mes de qualit√© de
donn√©es. Pour chaque probl√®me nous d√©cidons des actions √† entreprendre dans la phase de
pr√©paration des donn√©es.  
           
**1üîπ Valeurs manquantes**  
            
Nous remarquons plusieurs valeurs manquantes dans la colonne description (35% des donn√©es). Le champ
d√©signation est quant √† lui toujours renseign√©. Plusieurs strat√©gie s'offrent √† nous :  
&nbsp;&nbsp;&nbsp;&nbsp;‚Ä¢ Imputation par une cha√Æne vide ou une valeur par d√©faut (ex: "Pas de description
disponible").  
&nbsp;&nbsp;&nbsp;&nbsp;‚Ä¢ Suppression des lignes si le pourcentage reste g√©rable apr√®s analyse.  
&nbsp;&nbsp;&nbsp;&nbsp;‚Ä¢ Concat√©nation de la colonne d√©signation avec description pour cr√©er un seul champ texte.  
           
Apr√®s des textes de mod√©lisation lors de la phase de test nous remarquons de meilleurs r√©sulats
lorsque nous concat√©nons les deux champs. Nous choisissons donc cette strat√©gie.  
           
**2üîπ R√©partition des classes (prdtypecode)**  
           
Nous observons un d√©s√©quilibre important entre les diff√©rentes classes. Certaines classes
sont surrepr√©sent√©es tandis que d'autres sont tr√®s peu pr√©sentes. Cela peut biaiser le
mod√®le lors de l'entra√Ænement.  
""")
  st.image("images/Repartition_des_classes.png", use_container_width=False)
  st.write("""
Plusieurs options sont possibles :  
&nbsp;&nbsp;&nbsp;&nbsp;‚Ä¢ Sur√©chantillonnage des classes minoritaires (duplication de lignes, trduction en anglais,
re-traduction en fran√ßais)  
&nbsp;&nbsp;&nbsp;&nbsp;‚Ä¢ Sous-√©chantillonnage des classes majoritaires (suppression de lignes)  
&nbsp;&nbsp;&nbsp;&nbsp;‚Ä¢ Utilisation de techniques avanc√©es comme SMOTE pour g√©n√©rer des exemples synth√©tiques.  
&nbsp;&nbsp;&nbsp;&nbsp;‚Ä¢ Utilisation de class_weight dans le mod√®le pour g√©rer le d√©s√©quilibre.  
  
Apr√®s diff√©rents tests nous optons pour un class_weight="balanced" avec LinearSVC.  
           
**2üîπ D√©tection des langues**  
           
Nous constatons la pr√©sence de plusieurs langues dans les champs textes (fran√ßais, anglais,
espagnol, italien, allemand...). Pour l'efficacit√© du mod√®le nous d√©cidons de tout
traduire en fran√ßais.  
           
**üîπ Balises HTML et Stopwords dans les textes**  
           
Nous remarquons la pr√©sence de balises HTML dans les champs textes. Elles n'apportent
aucune valeur ajout√©e pour le mod√®le et sont m√™me contre-productives. Nous d√©cidons de toutes les
supprimer.  
Les Stopwords sont des mots courants (le, la, et, de, √†...) qui n'apportent pas
d'information pertinente pour la classification. Nous d√©cidons de les supprimer aussi.  
""")
  st.image("images/Stopwords.png", use_container_width=True)
  st.write("""
**üîπ Conclusion**  

L'analyse exploratoire des donn√©es nous montre qu'il est tr√®s important avant de commencer
l'entra√Ænement du mod√®le de passer par une phase de pr√©paration des donn√©es rigoureuse.  
Nous remarquons plusieurs probl√®mes de qualit√© de donn√©es dans le dataset textuel. Nous
avons identifi√© des strat√©gies pour chaque probl√®me qui seront mises en ≈ìuvre dans la phase
de pr√©paration des donn√©es afin d'am√©liorer la qualit√© des donn√©es avant l'entra√Ænement du
mod√®le.  
           
---  
### Exploration de la donn√©e image  
           
A venir ...
""")

#---------------------------------------PAGE PREPARATION DE LA DONNEE -----------------------------------------
if page == pages[2] : 
  affiche_bandeau("Pr√©paration des donn√©es", "#bf0000")
  st.write("""
### Split des donn√©es
Apr√®s l'exploration nous d√©cidons de splitter nos donn√©es r√©partit en 80% (train) et 20%
(test) avant le nettoyage des donn√©es.  
Nous g√©n√©rons donc 2 fichiers √† partir de \"X_train_update.csv\" (fichier source original) :  
üîπ \"X_train_non_nettoye_80.csv\"  
üîπ \"X_test_non_nettoye_20.csv\"

---
### Pr√©paration des donn√©es X_train_80

Suite √† l'analyse exploratoire des donn√©es nous avons identifi√© plusieurs actions √† faire
dans la pr√©paration des donn√©es avant de commencer √† entra√Æner le mod√®le.

**1üîπ Cr√©ation d'une colonne fusionn√©e de \"designation\" et \"description\"**  

Nous avons constat√© environ que 35% des donn√©es de \"description\" √©taient vides. Donc
nous avons fait le choix de fusionner les colonnes \"designation\" et \"description\" qui sont
toutes deux des champs textes. Nous ne supprimons pas la colonne \"description\" car elle
contient des donn√©es compl√©mentaires √† \"designation\" qui permettront au mod√®le
d'√™tre plus performant.

**2üîπ Supprimer les balises HTML**  

Nous avons relev√© la pr√©sence de balises HTML dans le champ \"description\". Elles n'ont
pas d'utilit√© pour le mod√®le et sont m√™me contre-productives. Par cons√©quent nous
supprimons toutes les balises pr√©sentes.

**3üîπ D√©tection de la langue (ajout d'une colonne pr√©cisant la langue)**  

L'exploration a remont√© la pr√©sence de texte en diff√©rentes langues. Donc nous ajoutons
une √©tape qui pr√©dit la langue pr√©sente dans le texte et la pr√©cise dans une colonne
ajout√©e. Ceci permettra par la suite de traduire en fran√ßais toutes les lignes qui ne sont
pas en \"fr\".  
Certaines donn√©es sont en plusieurs langues. Exemple : une description en fran√ßais avec
des mots anglais. Pour ce type de cas nous identifions la donn√©e comme \"fr\" et donc non
traduite.

**4üîπ Traduction des champs non fr (s'ex√©cute que si la nouvelle colonne langue** 
n'est pas en \"fr\")

Pour la traduction nous utilisons GoogleTranslator et faisons une sauvegarde toutes les
200 lignes traduites pour ne pas perdre l'avanc√©e en cas d'√©chec.

**5üîπ Suppression de la ponctuation et des stopwords** 

Certains mots viennent polluer le mod√®le comme \"le\", \"la\", \"et\" etc... Nous supprimons
ces mots (stop words). Nous supprimons tous les accents, la ponctuation. On met tout en
minuscules. On supprime les espaces en trop, les r√©p√©titions.  
Nous faisons des exceptions o√π nous transformons \"n¬∞\" en \"numero\" car cette donn√©e
est utile pour la pr√©diction des magazines. Nous gardons les chiffres car ils sont aussi
utiles pour les magazines, jeux vid√©o.

**6üîπ R√©√©quilibrage des classes**  
           
L'exploration a mis en √©vidence un d√©s√©quilibre des classes. Donc nous utiliserons plut√¥t  
un **class weight = balanced** dans le mod√®le qui g√©rera ce d√©s√©quilibre des classes.

**7üîπ Ensuite nous gardons que les colonnes utiles pour le mod√®le et sauvegardons
un fichier \"X_train_80_clean.csv\"**

---
### Pr√©paration des donn√©es X_test_20
Nous appliquons quasiment le m√™me code que pour X_train_80 sauf que nous ne faisons
pas de r√©√©quilibrage des classes donc les √©tapes sont les suivantes :  

1üîπ Cr√©ation d'une colonne fusionn√©e de \"designation\" et \"description\"  
2üîπ Supprimer les balises HTML  
3üîπ D√©tection de la langue (ajout d'une colonne pr√©cisant la langue)  
4üîπ Traduction des champs non fr (s'ex√©cute que si la nouvelle colonne langue
n'est pas en "fr")  
5üîπ Suppression de la ponctuation et des stopwords  
6üîπ Ensuite nous gardons que les colonnes utiles pour le test et sauvegardons un
fichier \"X_test_20_clean.csv\"
        """
    )


#---------------------------------------PAGE MODELISATION TEXTE-----------------------------------------
if page == pages[3] : 
  affiche_bandeau("Mod√©lisation sur le texte", "#bf0000")
  st.write("""

#### üîπ Choix des donn√©es  

Dans un premier temps, nous avons utilis√© des donn√©es pr√©par√©es vues pr√©c√©demment :  
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;‚Ä¢ **Nettoyage des balises HTML** pour ne conserver que le texte pertinent.  
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;‚Ä¢ Suppression des **stopwords**.  
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;‚Ä¢ **Traduction** des textes en fran√ßais afin d‚Äôuniformiser le langage.  
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;‚Ä¢ Concat√©nation des champs **designation** et **description** en une seule colonne texte.           
 
Ensuite, pour g√©rer le d√©s√©quilibre des classes, nous avons choisi d‚Äôharmoniser la
volum√©trie par classe entre **1000 et 4000 produits**.Donc pour les classes 
surdimensionn√©es nous avons effectu√© des suppressions de donn√©es et pour les classes 
sous dimensionn√©es nous avons dupliqu√© al√©atoirement des lignes. 

---

####  üîπ Entra√Ænement de mod√®les 

Le mod√®le initial consistait en une vectorisation TF-IDF combin√©e √† un mod√®le de classification 
Logistic Regression, entra√Æn√© sur les donn√©es pr√©par√©es du champ concat√©nant designation et description.  
Ce mod√®le a atteint un score f1 weighted **78,39 %**.  
Ensuite, nous avons test√© **TF-IDF combin√© √† LinearSVC**, avec un score de **78,55 %**.  
""")
  st.image("images/Matrice_confusion_texte.png", use_container_width=True)    
  st.write("""      
Apr√®s analyse des erreurs via une matrice de confusion, nous avons remarqu√© que certaines
cat√©gories √©taient souvent confondues entre elles, notamment les sous-cat√©gories de Livres et de Jeux vid√©o.
Pour tenter d‚Äôam√©liorer les performances, nous avons ajout√© des features
sp√©cifiques pour ces cat√©gories.  

De plus nous avons fait machine arri√®re pour g√©rer le d√©s√©quilibre des classes en choisissant de tout garder mais 
d‚Äôutiliser class_weight="balanced" dans le LinearSVC. Nous avons aussi ajout√© des param√®tres √† TF-IDF 
sur les mots et les caract√®res (word_tfidf et char_tfidf) : **Score : 81,72%**  

---

####  üîπ Optimisation des param√®tres  

Pour continuer, nous avons test√© plusieurs param√®tres diff√©rents pour **TF-IDF** et **LinearSVC** :  

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;‚Ä¢ Word n-gram : 1,2 / 1,3  
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;‚Ä¢ Char n-gram : 3,5 / 2,4 / 4,6  
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;‚Ä¢ Max features : 120 000 / 80 000 / 150 000  
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;‚Ä¢ Min_df : 1 / 2  
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;‚Ä¢ LinearSVC C : 1.5 / 1.6 / 1.8 / 2.0  

**Meilleure combinaison retenue** :  
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;‚Ä¢  Word n-gram : 1,2  
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;‚Ä¢  Char n-gram : 3,5  
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;‚Ä¢  Max features : 120 000  
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;‚Ä¢  Min_df : 1  
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;‚Ä¢  LinearSVC C : 1.5  

Pour un score de **83,06 %**.

---

####  üîπ Tests de mod√®les Deep Learning  

Ensuite nous avons voulu essayer des mod√®les de deep learning (XGBoost, Random Forest, CamenBERT). 
La difficult√© est surtout li√©e √† nos machines. Nous n‚Äô√©tions pas assez bien √©quip√©s pour lancer des
mod√®les de ce type : l‚Äôentra√Ænement dure des heures, la m√©moire surcharge et l'entra√Ænement s'arr√™te,
sur des GPU cloud des time-out nous freinaient dans nos apprentissages.  

Nous avons tant bien que mal r√©ussi √† avoir des r√©sultats mais avec le minimum de param√®tres :   
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;‚Ä¢  XGBoost : 79%  
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;‚Ä¢  CamenBERT : 77%  
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;‚Ä¢  Random Forest : jamais r√©ussi √† aller au bout.    

---

#### üîπ Am√©lioration du mod√®le TF-IDF + LinearSVC  

√âtant bloqu√© par la puissance de nos machines nous avons tent√© d‚Äôam√©liorer le mod√®le TF-IDF + LinearSVC.
N‚Äôy arrivant pas, nous prenons la d√©cision de tester notre meilleur mod√®le sur les donn√©es brut tel quel
et ensuite avancer par √©tape pour la transformation des donn√©es :   
""")
  st.markdown("""
&nbsp;&nbsp;&nbsp;&nbsp;‚Ä¢ Donn√©es brut - sur champ d√©signation :
<span style='color:green; font-weight:bold;'>‚≠° 83,75%</span><br>
&nbsp;&nbsp;&nbsp;&nbsp;‚Ä¢ Donn√©es sans balise HTML et Stopwords :
<span style='color:red; font-weight:bold;'>‚≠£ 82,38%</span><br>
&nbsp;&nbsp;&nbsp;&nbsp;‚Ä¢ Donn√©es brut - sur champ d√©signation sans Features dans le mod√®le :
<span style='color:green; font-weight:bold;'>‚≠° 83,70%</span><br>
&nbsp;&nbsp;&nbsp;&nbsp;‚Ä¢ Donn√©es sans balise HTML et Stopwords sans Features dans le mod√®le :
<span style='color:red; font-weight:bold;'>‚≠£ 82,40%</span><br>
&nbsp;&nbsp;&nbsp;&nbsp;‚Ä¢ Donn√©es brut - sans features - d√©signation+description :
<span style='color:green; font-weight:bold;'>‚≠° 84,92%</span><br>
&nbsp;&nbsp;&nbsp;&nbsp;‚Ä¢ Donn√©es brut - sans features - d√©signation avec 2 fois plus de poids que description :
<span style='color:green; font-weight:bold;'>‚≠° 85,61%</span><br>
&nbsp;&nbsp;&nbsp;&nbsp;‚Ä¢ Donn√©es brut - sans features - d√©signation avec 3 fois plus de poids que description :
<span style='color:green; font-weight:bold;'>‚≠° 85,71%</span><br>
&nbsp;&nbsp;&nbsp;&nbsp;‚Ä¢ Donn√©es brut - sans features - d√©signation avec 4 fois plus de poids que description :
<span style='color:green; font-weight:bold;'>‚≠° 85,75%</span><br>
&nbsp;&nbsp;&nbsp;&nbsp;‚Ä¢ Donn√©es brut - sans features - d√©signation avec 5 fois plus de poids que description :
<span style='color:red; font-weight:bold;'>‚≠£ 85,70%</span><br>
&nbsp;&nbsp;&nbsp;&nbsp;‚Ä¢ Donn√©es brut - sans features - d√©signation x4 + description + unit√© de mesure :
<span style='color:green; font-weight:bold;'>‚≠° 85,81%</span><br>
&nbsp;&nbsp;&nbsp;&nbsp;‚Ä¢ Donn√©es brut - sans features - d√©signation x4 + description + unit√© de mesure + ajout de poids des 3 premiers mots de d√©signation :
<span style='color:green; font-weight:bold;'>‚≠° 86,06%</span><br>
&nbsp;&nbsp;&nbsp;&nbsp;‚Ä¢ Donn√©es brut - sans features - d√©signation x4 + description + unit√© de mesure + ajout de poids des 3 premiers mots de d√©signation : changement de m√©thode (pond√©ration directement dans le TF-IDF) : Meilleur score : <span style='color:green; font-weight:bold;'>‚≠° 86,22%</span>  
Je ne fais plus de concat√©nation √† la main mais je choisis une approche Pipeline + ColumnTransformer, donc chaque feature est une m√©thode ind√©pendante, bien s√©par√©e, tra√ßable et r√©utilisable.
""", unsafe_allow_html=True)

  st.image("images/Graphique_des_modeles.png", use_container_width=True)  


  st.write("""
---

####  üîπ Soumission au challenge  

Nous avons soumis notre meilleur mod√®le en phase de test au challenge Rakuten et obtenu le score de **87,41%**. Pour rappel il fallait un score de 81,13% pour la r√©ussite de ce challenge.  

---

#### üîπ Autres mod√®les  

Nous avons souhait√© tester notre meilleur mod√®le sur les donn√©es d'entra√Ænement en regroupant certaines classes. Toutes les classes concernant les livres en une seule classe et pareil pour les jeux vid√©o et consoles. Nous avons aussi regroup√© en une seule classe les jeux de soci√©t√©s et les jouets pour enfants :   

&nbsp;&nbsp;&nbsp;&nbsp;‚Ä¢ **Livres** : Livres loisirs et soci√©t√© + Lots Livres & Magazines + Magazines + Livres litt√©rature et fiction  
&nbsp;&nbsp;&nbsp;&nbsp;‚Ä¢ **Jeux vid√©o** : Jeux vid√©o + Accessoires jeux vid√©o + Jeux vid√©o & Consoles + Lots consoles & jeux  
&nbsp;&nbsp;&nbsp;&nbsp;‚Ä¢ **Jeux & Enfants** : Jouets & Enfant + Jeux de soci√©t√©  
  
**Score obtenu : 90,91 %**.

""")
#---------------------------------------PAGE MODELISATION TEXTE-----------------------------------------
if page == pages[4] : 
  affiche_bandeau("Mod√©lisation sur le texte", "#bf0000")
  st.write("""
           

""")
#---------------------------------------PAGE TESTER LE MODELE (version simplifi√©e) -----------------------------------------


if page == "Tester le mod√®le":
    import os
    import re
    import joblib
    import streamlit as st
    import pandas as pd
    import requests

    st.header("Tester le mod√®le")
    st.write("Entrez la d√©signation et la description du produit pour pr√©dire sa cat√©gorie :")

    # =========================
    # Inputs utilisateur
    # =========================
    designation_input = st.text_input("D√©signation produit")
    description_input = st.text_area("Description produit", height=150)

    # ============================================================
    # FONCTIONS CUSTOM (n√©cessaires pour joblib.load)
    # ============================================================
    UNIT_PATTERN = r"(cm|mm|m|kg|g|mg|l|ml|cl|w|kw|v|mah|ah|hz|ghz|mhz|go|gb|to|tb|mp|px|fps|¬∞c|¬∞)"

    def get_designation(X):
        return X["designation"].fillna("").astype(str)

    def get_description(X):
        return X["description"].fillna("").astype(str)

    def first_words_series(X, n=3):
        return (
            X["designation"]
            .fillna("")
            .astype(str)
            .str.lower()
            .str.split()
            .str[:n]
            .str.join(" ")
        )

    def numbers_units_series(X):
        return (
            X["designation"]
            .fillna("")
            .astype(str)
            .str.lower()
            .str.findall(rf"\b\d+[.,]?\d*\s?{UNIT_PATTERN}\b")
            .str.join(" ")
        )

    # =========================
    # Chargement du mod√®le depuis Dropbox
    # =========================
    MODEL_URL = (
        "https://www.dropbox.com/scl/fi/oole37javo3jpageyx80v/"
        "modele_final_rakuten.pkl?rlkey=wh7c65m17gyivk7wy0jgu377k&dl=1"
    )
    MODEL_PATH = "modele_final_rakuten.pkl"

    @st.cache_resource
    def load_pipeline():
        if not os.path.exists(MODEL_PATH):
            with st.spinner("üì• T√©l√©chargement du mod√®le..."):
                r = requests.get(MODEL_URL)
                r.raise_for_status()
                with open(MODEL_PATH, "wb") as f:
                    f.write(r.content)
        return joblib.load(MODEL_PATH)

    pipe = load_pipeline()

    # =========================
    # Chargement du mapping
    # =========================
    BASE_DIR = os.path.dirname(__file__)
    mapping_path = os.path.join(BASE_DIR, "Y_train_encode.csv")

    mapping_df = pd.read_csv(mapping_path)
    mapping_df = mapping_df.drop_duplicates(subset=["prdtypecode_encoded"])

    mapping = mapping_df.set_index("prdtypecode_encoded")["libelle_type_code"].to_dict()

    # =========================
    # Pr√©diction
    # =========================
    if st.button("Valider"):
        if not designation_input.strip() and not description_input.strip():
            st.warning("Veuillez saisir au moins la d√©signation ou la description.")
        else:
        # Cr√©ation d'un DataFrame 1 ligne pour respecter le format du pipeline
            input_df = pd.DataFrame([{
                "designation": designation_input,
                "description": description_input
            }])

        # Pr√©diction
            pred = pipe.predict(input_df)[0]
            label = mapping.get(pred)

            if label:
                st.success(f"üîπ Cat√©gorie pr√©dite : **{label}**")
            else:
                st.success("üîπ Cat√©gorie pr√©dite : Non disponible")
