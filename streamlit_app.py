from importlib.resources import path
import streamlit as st
import joblib


st.set_page_config(
    page_title="Rakuten AVR25CDS",   # titre affich√© dans l'onglet du navigateur
    page_icon="images/favicon_Rakuten.png",             # emoji ou chemin vers une ic√¥ne .png
    layout="centered"               # optionnel : wide ou centered
)

st.markdown("""
    <div style="
    position: fixed;   /* fixe le bandeau en haut */
    top: 60px;
    left: 100px;
    width: 100%;       /* s'√©tend sur toute la largeur */
    height: 70px;      /* hauteur du bandeau */
    display: flex;     /* active Flexbox */
    align-items: center; /* centre verticalement */
    justify-content: center; /* centre horizontalement */
    background-color: #efefef; 
    z-index: 1000;      /* pour rester au-dessus des autres √©l√©ments */
">
    <h3 style="color: #bf0000; margin: 0;">
        Classification des donn√©es produits multimodales de Rakuten France
    </h3>
</div>

<!-- Evite que le contenu soit cach√© par le bandeau -->
<div style="margin-top:70px;"></div>
""", unsafe_allow_html=True)

# --- TRAIT SEPARATION ---

st.markdown("""
            ---
  """, unsafe_allow_html=True)

# --------------------- STYLE PERSONNALIS√â POUR LE MENU DE GAUCHE SIDEBAR ---
st.markdown("""
    <style>
    /* Couleur de fond de la sidebar */
    section[data-testid="stSidebar"] {
        background-color: #efefef;   
    }

    /* Couleur du texte dans la sidebar */
    section[data-testid="stSidebar"] * {
        color: #bf0000 !important;    
    }
    </style>
""", unsafe_allow_html=True)




# === LOGO + SOMMAIRE DANS LA SIDEBAR ===
# --- Sidebar ---
with st.sidebar:
    st.image("images/rakuten.png", use_container_width=True)
    st.markdown("<br>", unsafe_allow_html=True)
    st.title("Sommaire")

    pages = ["Pr√©sentation du projet","Exploration", "Pr√©paration", "Mod√©lisation","Tester le mod√®le"]
    page = st.radio("", pages)

    # --- Auteurs ---
    st.markdown("<hr>", unsafe_allow_html=True)
    st.markdown(
        """
        **Auteurs :**  
        Angella FONTAINE  
        Fatiha IDDER  
        Julien RAOULT
        """,
        unsafe_allow_html=True
    )


# --- TITRE DE CHAQUE PAGE ---
def affiche_bandeau(titre, couleur_fond="#bf0000"):
    st.markdown(f"""
        <div style="
            /*background-color: {couleur_fond};*/
            padding: 3px;
            border-radius: 5px;
            text-align: center;
            height:60px;
        ">
            <h3 style="color: #bf0000; margin: 0;">{titre}</h3>
        </div>
        <br>
    """, unsafe_allow_html=True)



# === CONTENU DES PAGES ===
#---------------------------------------PAGE PRESENTATION DU PROJET -----------------------------------------
if page == pages[0] : 
  affiche_bandeau("Pr√©sentation du projet", "#bf0000")
  st.write("""
###  Contexte Rakuten  

Rakuten est un des plus grands acteurs mondiaux du e-commerce, cr√©√© en 1997, 
avec plus de **1,3 milliard d‚Äôutilisateurs** dans son √©cosyst√®me international.
Le **Rakuten Institute of Technology (RIT)** m√®ne des recherches en apprentissage automatique,
vision par ordinateur, NLP et HCI, avec des √©quipes √† Tokyo, Paris, Boston, Singapour et Bengaluru.  
           
### Objectif du projet  
           
Cr√©er un mod√®le capable de **classer automatiquement les produits** du catalogue Rakuten France
dans leur code type produit (prdtypecode), en utilisant du texte (titre, description) et/ou des images.
C‚Äôest un probl√®me de **classification multimodale** √† grande √©chelle.  
           
### Contexte du challenge  

Cat√©goriser les produits est un enjeu crucial pour les marketplaces (recherche, recommandation, compr√©hension des requ√™tes).
Les approches manuelles ou bas√©es sur des r√®gles ne sont pas scalables.
Le d√©fi est difficile √† cause de :  
&nbsp;&nbsp;&nbsp;&nbsp;‚Ä¢ Donn√©es textuelles bruyantes  
&nbsp;&nbsp;&nbsp;&nbsp;‚Ä¢ Images vari√©es et h√©t√©rog√®nes  
&nbsp;&nbsp;&nbsp;&nbsp;‚Ä¢ Grand nombre de classes  
&nbsp;&nbsp;&nbsp;&nbsp;‚Ä¢ Distribution d√©s√©quilibr√©e  
&nbsp;&nbsp;&nbsp;&nbsp;‚Ä¢ Qualit√© in√©gale des informations fournies par les vendeurs  
Le challenge consiste √† exploiter texte + image pour construire un classifieur performant.  
           
### Description du probl√®me  

Pour chaque produit (avec titre, image, parfois description), pr√©dire son prdtypecode.  
Exemple : Klarstein Pr√©sentoir 2 Montres‚Ä¶ ‚Üí cat√©gorie produit 1500.  
Les donn√©es ressemblent √† :  
&nbsp;&nbsp;&nbsp;&nbsp;‚Ä¢ Designation : titre du produit  
&nbsp;&nbsp;&nbsp;&nbsp;‚Ä¢ Description : texte descriptif (souvent manquant)  
&nbsp;&nbsp;&nbsp;&nbsp;‚Ä¢ Productid et imageid : permettent de retrouver l‚Äôimage  
&nbsp;&nbsp;&nbsp;&nbsp;‚Ä¢ Image : une seule image par produit  
&nbsp;&nbsp;&nbsp;&nbsp;‚Ä¢ Prdtypecode : label √† pr√©dire  
           
### Jeu de donn√©es  

Rakuten fournit environ 99 000 produits :  
&nbsp;&nbsp;&nbsp;&nbsp;‚Ä¢ X_train (84 916) : textes + images  
&nbsp;&nbsp;&nbsp;&nbsp;‚Ä¢ Y_train : prdtypecode pour chaque id  
&nbsp;&nbsp;&nbsp;&nbsp;‚Ä¢ X_test (13 812) : textes + images √† pr√©dire  
&nbsp;&nbsp;&nbsp;&nbsp;‚Ä¢ images.zip : dossier contenant toutes les images (train/test s√©par√©es)  
           
### Objectif  
L'objectif est d'obtenir un F1-score sup√©rieur √† **0,8113 sur les donn√©es textuelles**.  
Pour les **images**, l'objectif est d'atteindre un F1-score sup√©rieur √† **0,5534**.
""")
#---------------------------------------PAGE EXPLORATION DE LA DONNEE -----------------------------------------
if page == pages[1] : 
  affiche_bandeau("Exploration des donn√©es", "#bf0000")
  st.write("""
### Exploration de la donn√©e textuelle  

#### üîé Visualisation du dataset  
Structure du dataset X  
""")
  st.image("images/Visualisation_X.png", use_container_width=True)
  st.write("""
Structure du dataset Y  
""")
  st.image("images/Visualisation_Y.png", use_container_width=False)
  st.write("""
#### ‚úÖ Qualit√© de la donn√©e 
Lors de l'exploration du dataset nous identifions plusieurs probl√®mes de qualit√© de
donn√©es. Pour chaque probl√®me nous d√©cidons des actions √† entreprendre dans la phase de
pr√©paration des donn√©es.  
           
**1üîπ Valeurs manquantes**  
            
Nous remarquons plusieurs valeurs manquantes dans la colonne description (35% des donn√©es). Le champ
d√©signation est quant √† lui toujours renseign√©. Plusieurs strat√©gie s'offrent √† nous :  
&nbsp;&nbsp;&nbsp;&nbsp;‚Ä¢ Imputation par une cha√Æne vide ou une valeur par d√©faut (ex: "Pas de description
disponible").  
&nbsp;&nbsp;&nbsp;&nbsp;‚Ä¢ Suppression des lignes si le pourcentage reste g√©rable apr√®s analyse.  
&nbsp;&nbsp;&nbsp;&nbsp;‚Ä¢ Concat√©nation de la colonne d√©signation avec description pour cr√©er un seul champ texte.  
           
Apr√®s des textes de mod√©lisation lors de la phase de test nous remarquons de meilleurs r√©sulats
lorsque nous concat√©nons les deux champs. Nous choisissons donc cette strat√©gie.  
           
**2üîπ R√©partition des classes (prdtypecode)**  
           
Nous observons un d√©s√©quilibre important entre les diff√©rentes classes. Certaines classes
sont surrepr√©sent√©es tandis que d'autres sont tr√®s peu pr√©sentes. Cela peut biaiser le
mod√®le lors de l'entra√Ænement.  
""")
  st.image("images/Repartition_des_classes.png", use_container_width=False)
  st.write("""
Plusieurs options sont possibles :  
&nbsp;&nbsp;&nbsp;&nbsp;‚Ä¢ Sur√©chantillonnage des classes minoritaires (duplucation de lignes, trduction en anglais,
re-traduction en fran√ßais)  
&nbsp;&nbsp;&nbsp;&nbsp;‚Ä¢ Sous-√©chantillonnage des classes majoritaires (suppression de lignes)  
&nbsp;&nbsp;&nbsp;&nbsp;‚Ä¢ Utilisation de techniques avanc√©es comme SMOTE pour g√©n√©rer des exemples synth√©tiques.  
&nbsp;&nbsp;&nbsp;&nbsp;‚Ä¢ Utilisation de class_weight dans le mod√®le pour g√©rer le d√©s√©quilibre.  
  
Apr√®s diff√©rents tests nous optons pour un class_weight="balanced" avec LinearSVC.  
           
**2üîπ D√©tection des langues**  
           
Nous constatons la pr√©sence de plusieurs langues dans les champs textes (fran√ßais, anglais,
espagnol, italien, allemand...). Pour l'efficacit√© du mod√®le nous d√©cidons de tout
traduire en fran√ßais.  
           
**üîπ Balises HTML et Stopwords dans les textes**  
           
Nous remarquons la pr√©sence de balises HTML dans les champs textes. Elles n'apportent
aucune valeur ajout√©e pour le mod√®le et sont m√™me contre-productives. Nous d√©cidons de toutes les
supprimer.  
Les Stopwords sont des mots courants (le, la, et, de, √†...) qui n'apportent pas
d'information pertinente pour la classification. Nous d√©cidons de les supprimer aussi.  
""")
  st.image("images/Stopwords.png", use_container_width=True)
  st.write("""
**üîπ Conclusion**  

L'analyse exploratoire des donn√©es nous montre qu'il est tr√®s important avant de commencer
l'entra√Ænement du mod√®le de passer par une phase de pr√©paration des donn√©es rigoureuse.  
Nous remarquons plusieurs probl√®mes de qualit√© de donn√©es dans le dataset textuel. Nous
avons identifi√© des strat√©gies pour chaque probl√®me qui seront mises en ≈ìuvre dans la phase
de pr√©paration des donn√©es afin d'am√©liorer la qualit√© des donn√©es avant l'entra√Ænement du
mod√®le.  
           
---  
### Exploration de la donn√©e image  
           
A venir ...
""")

#---------------------------------------PAGE PREPARATION DE LA DONNEE -----------------------------------------
if page == pages[2] : 
  affiche_bandeau("Pr√©paration des donn√©es", "#bf0000")
  st.write("""
### Split des donn√©es
Apr√®s l'exploration nous d√©cidons de splitter nos donn√©es r√©partit en 80% (train) et 20%
(test) avant le nettoyage des donn√©es.  
Nous g√©n√©rons donc 2 fichiers √† partir de \"X_train_update.csv\" (fichier source original) :  
üîπ \"X_train_non_nettoye_80.csv\"  
üîπ \"X_test_non_nettoye_20.csv\"

---
### Pr√©paration des donn√©es X_train_80

Suite √† l'analyse exploratoire des donn√©es nous avons identifi√© plusieurs actions √† faire
dans la pr√©paration des donn√©es avant de commencer √† entra√Æner le mod√®le.

**1üîπ Cr√©ation d'une colonne fusionn√©e de \"designation\" et \"description\"**  

Nous avons constat√© environ que 35% des donn√©es de \"description\" √©taient vides. Donc
nous avons fait le choix de fusionner les colonnes \"designation\" et \"description\" qui sont
toutes deux des champs textes. Nous ne supprimons pas la colonne \"description\" car elle
contient des donn√©es compl√©mentaires √† \"designation\" qui permettront au mod√®le
d'√™tre plus performant.

**2üîπ Supprimer les balises HTML**  

Nous avons relev√© la pr√©sence de balises HTML dans le champ \"description\". Elles n'ont
pas d'utilit√© pour le mod√®le et sont m√™me contre-productives. Par cons√©quent nous
supprimons toutes les balises pr√©sentes.

**3üîπ D√©tection de la langue (ajout d'une colonne pr√©cisant la langue)**  

L'exploration a remont√© la pr√©sence de texte en diff√©rentes langues. Donc nous ajoutons
une √©tape qui pr√©dit la langue pr√©sente dans le texte et la pr√©cise dans une colonne
ajout√©e. Ceci permettra par la suite de traduire en fran√ßais toutes les lignes qui ne sont
pas en \"fr\".  
Certaines donn√©es sont en plusieurs langues. Exemple : une description en fran√ßais avec
des mots anglais. Pour ce type de cas nous identifions la donn√©e comme \"fr\" et donc non
traduite.

**4üîπ Traduction des champs non fr (s'ex√©cute que si la nouvelle colonne langue** 
n'est pas en \"fr\")

Pour la traduction nous utilisons GoogleTranslator et faisons une sauvegarde toutes les
200 lignes traduites pour ne pas perdre l'avanc√©e en cas d'√©chec.

**5üîπ Suppression de la ponctuation et des stopwords** 

Certains mots viennent polluer le mod√®le comme \"le\", \"la\", \"et\" etc... Nous supprimons
ces mots (stop words). Nous supprimons tous les accents, la ponctuation. On met tout en
minuscules. On supprime les espaces en trop, les r√©p√©titions.  
Nous faisons des exceptions o√π nous transformons \"n¬∞\" en \"numero\" car cette donn√©e
est utile pour la pr√©diction des magazines. Nous gardons les chiffres car ils sont aussi
utiles pour les magazines, jeux vid√©o.

**6üîπ R√©√©quilibrage des classes**  
           
L'exploration a mis en √©vidence un d√©s√©quilibre des classes. Donc nous utiliserons plut√¥t  
un **class weight = balanced** dans le mod√®le qui g√©rera ce d√©s√©quilibre des classes.

**7üîπ Ensuite nous gardons que les colonnes utiles pour le mod√®le et sauvegardons
un fichier \"X_train_80_clean.csv\"**

---
### Pr√©paration des donn√©es X_test_20
Nous appliquons quasiment le m√™me code que pour X_train_80 sauf que nous ne faisons
pas de r√©√©quilibrage des classes donc les √©tapes sont les suivantes :  

1üîπ Cr√©ation d'une colonne fusionn√©e de \"designation\" et \"description\"  
2üîπ Supprimer les balises HTML  
3üîπ D√©tection de la langue (ajout d'une colonne pr√©cisant la langue)  
4üîπ Traduction des champs non fr (s'ex√©cute que si la nouvelle colonne langue
n'est pas en "fr")  
5üîπ Suppression de la ponctuation et des stopwords  
6üîπ Ensuite nous gardons que les colonnes utiles pour le test et sauvegardons un
fichier \"X_test_20_clean.csv\"
        """
    )

#---------------------------------------PAGE MODELISATION -----------------------------------------
if page == pages[3] : 
  affiche_bandeau("Mod√©lisation sur le texte", "#bf0000")
  st.write("""

#### Notre mod√®le se caract√©rise en 4 points :  
1üîπ TF-IDF sur les mots  
2üîπ TF-IDF sur les caract√®res  
3üîπ Features heuristiques sp√©cifiques aux jeux vid√©o  
4üîπ SVM lin√©aire (LinearSVC)  
5üîπ R√©sultat du mod√®le lors du test

---

#### 1üîπ TF-IDF sur les mots  
           
üî∏ TF-IDF signifie Term Frequency ‚Äì Inverse Document Frequency.  
üî∏ Il transforme chaque texte en vecteur num√©rique o√π chaque dimension
correspond √† un mot ou un bigramme (paire de mots).  
üî∏ L‚Äôid√©e :  
&nbsp;&nbsp;&nbsp;&nbsp;‚Ä¢ TF (Term Frequency) : un mot fr√©quent dans un texte obtient un score
√©lev√©.  
&nbsp;&nbsp;&nbsp;&nbsp;‚Ä¢ IDF (Inverse Document Frequency) : un mot tr√®s courant dans tous les
textes (comme ‚Äúle‚Äù, ‚Äúet‚Äù) est moins important.  
üî∏ R√©sultat : les mots qui sont sp√©cifiques et informatifs pour une cat√©gorie de
produit ont plus de poids.  
           
#### 2üîπ TF-IDF sur les caract√®res  
           
üî∏ M√™me principe que TF-IDF sur les mots, mais appliqu√© √† des s√©quences de
caract√®res (3 √† 5 lettres cons√©cutives).  
üî∏ Objectif :  
&nbsp;&nbsp;&nbsp;&nbsp;‚Ä¢ Capturer des variantes orthographiques, fautes de frappe ou abr√©viations.  
&nbsp;&nbsp;&nbsp;&nbsp;‚Ä¢ Exemple : ‚ÄúPlayStation‚Äù ‚Üí ‚Äúpla‚Äù, ‚Äúlay‚Äù, ‚Äúays‚Äù, ‚Ä¶  
&nbsp;&nbsp;&nbsp;&nbsp;‚Ä¢ Utile quand les noms de produits peuvent √™tre √©crits de fa√ßons l√©g√®rement  
diff√©rentes.  
           
#### 3üîπ Features heuristiques sp√©cifiques aux jeux vid√©o  
           
üî∏ Ce sont des indicateurs binaires (0 ou 1) ajout√©s aux vecteurs TF-IDF pour
enrichir le mod√®le.  
üî∏ Exemple d‚Äôindicateurs :  
&nbsp;&nbsp;&nbsp;&nbsp;‚Ä¢ Pr√©sence de plateformes : ps4, xbox, switch, etc.  
&nbsp;&nbsp;&nbsp;&nbsp;‚Ä¢ Pr√©sence de √©diteurs : Ubisoft, EA, Rockstar‚Ä¶  
&nbsp;&nbsp;&nbsp;&nbsp;‚Ä¢ Pr√©sence de franchises c√©l√®bres : Fifa, Call of Duty, Zelda‚Ä¶  
&nbsp;&nbsp;&nbsp;&nbsp;‚Ä¢ Indicateurs √©dition sp√©ciale : collector, deluxe, goty‚Ä¶  
&nbsp;&nbsp;&nbsp;&nbsp;‚Ä¢ Pr√©sence de PEGI ou d‚Äôune ann√©e de sortie r√©cente (>2000)  
           
üî∏ Ces features aident le mod√®le √† diff√©rencier les jeux vid√©o des autres produits,
comme les films ou les livres. 
            
Exemple avec le mot nintendo dans un texte : Dans les features heuristiques GameHeuristicFeatures : ¬´ nintendo ¬ª est dans la liste platform_kw. Si le texte contient ce
mot (apr√®s mise en minuscules et suppression des accents), la feature has_platform
prend la valeur 1. Cela ajoute une information binaire suppl√©mentaire au vecteur de
caract√©ristiques. Les deux types de signaux (poids TF-IDF et indicateur binaire) sont
fusionn√©s dans FeatureUnion et pass√©s au classifieur LinearSVC. Le SVM ne d√©cide pas
directement ¬´ nintendo = cat√©gorie X ¬ª, mais il utilise ces valeurs comme entr√©es pour
calculer un score pour chaque classe. Si ¬´ nintendo ¬ª est fortement corr√©l√© √† une
cat√©gorie dans les donn√©es d‚Äôentra√Ænement, son poids et/ou l‚Äôindicateur binaire vont
influencer la d√©cision finale en faveur de cette cat√©gorie.  
           
#### 4üîπ SVM lin√©aire (LinearSVC)  
           
üî∏ SVM (Support Vector Machine) : un mod√®le qui s√©pare les donn√©es en
diff√©rentes cat√©gories en trouvant une fronti√®re optimale dans l‚Äôespace des
caract√©ristiques.  
üî∏ LinearSVC : SVM avec un hyperplan lin√©aire, efficace pour les grands vecteurs
creux (comme les TF-IDF).  
üî∏ Avantages :  
&nbsp;&nbsp;&nbsp;&nbsp;‚Ä¢ Rapide et efficace pour des donn√©es textuelles volumineuses.  
&nbsp;&nbsp;&nbsp;&nbsp;‚Ä¢ G√®re les classes d√©s√©quilibr√©es gr√¢ce √† class_weight="balanced".  
(Contradictoire avec notre r√©√©quilibrage des classes en sur ou sous
dimensionnant mais nous nous en sommes rendu compte apr√®s la phase de
pr√©paration des donn√©es. Donc le r√©√©quilibrage sera supprim√© de la phase
pr√©paratoire et class_weight="balanced" sera directement dans le mod√®le
d'entra√Ænement)  
&nbsp;&nbsp;&nbsp;&nbsp;‚Ä¢ Peut √™tre combin√© avec des features suppl√©mentaires (TF-IDF +
heuristiques).  
           
**En gros, le pipeline fonctionne ainsi :**   
üî∏ 1.Transformer chaque texte en vecteur num√©rique avec TF-IDF sur mots +
caract√®res.  
üî∏ 2.Ajouter des features sp√©cifiques aux jeux vid√©o.  
üî∏ 3.Le SVM lin√©aire apprend √† s√©parer les cat√©gories de produits dans cet espace
de caract√©ristiques et g√®re le d√©s√©quilibre des classes.  
         
#### 5üîπ R√©sultat du mod√®le lors du test 
üî∏ Le mod√®le obtient un F1-score de 82,91%, d√©passant l'objectif de 81,13%  
üî∏ Le mod√®le est moins performant sur l'univers des jeux (jeux vid√©os, Jeux de
r√¥les, jeux de soci√©t√©) et les livres (Livres loisirs & soci√©t√©, Litt√©rature, Lots livres &
magazines)  
üî∏ Prochaine √©tape :  
&nbsp;&nbsp;&nbsp;&nbsp;‚Ä¢ Analyser les mauvaises pr√©dictions, trouver des features pour aider le
mod√®le √† mieux pr√©dire ces classes.  
&nbsp;&nbsp;&nbsp;&nbsp;‚Ä¢ Entra√Æner le mod√®le en utilisant un GPU pour acc√©l√©rer les calculs.  
&nbsp;&nbsp;&nbsp;&nbsp;‚Ä¢ Tester les performances du mod√®le sur GPU et CPU.  
&nbsp;&nbsp;&nbsp;&nbsp;‚Ä¢ Entra√Æner et √©valuer le mod√®le avec CamemBERT et Random Forest pour
comparer leurs performances avec le mod√®le actuel TF-IDF + LinearSVC.   
""")

#---------------------------------------PAGE TESTER LE MODELE (version simplifi√©e) -----------------------------------------


if page == "Tester le mod√®le":
    import os
    import re
    import joblib
    import streamlit as st
    import pandas as pd
    import requests

    st.header("Tester le mod√®le")
    st.write("Entrez la d√©signation et la description du produit pour pr√©dire sa cat√©gorie :")

    # =========================
    # Inputs utilisateur
    # =========================
    designation_input = st.text_input("D√©signation produit")
    description_input = st.text_area("Description produit", height=150)

    # ============================================================
    # FONCTIONS CUSTOM (n√©cessaires pour joblib.load)
    # ============================================================
    UNIT_PATTERN = r"(cm|mm|m|kg|g|mg|l|ml|cl|w|kw|v|mah|ah|hz|ghz|mhz|go|gb|to|tb|mp|px|fps|¬∞c|¬∞)"

    def get_designation(X):
        return X["designation"].fillna("").astype(str)

    def get_description(X):
        return X["description"].fillna("").astype(str)

    def first_words_series(X, n=3):
        return (
            X["designation"]
            .fillna("")
            .astype(str)
            .str.lower()
            .str.split()
            .str[:n]
            .str.join(" ")
        )

    def numbers_units_series(X):
        return (
            X["designation"]
            .fillna("")
            .astype(str)
            .str.lower()
            .str.findall(rf"\b\d+[.,]?\d*\s?{UNIT_PATTERN}\b")
            .str.join(" ")
        )

    # =========================
    # Chargement du mod√®le depuis Dropbox
    # =========================
    MODEL_URL = (
        "https://www.dropbox.com/scl/fi/oole37javo3jpageyx80v/"
        "modele_final_rakuten.pkl?rlkey=wh7c65m17gyivk7wy0jgu377k&dl=1"
    )
    MODEL_PATH = "modele_final_rakuten.pkl"

    @st.cache_resource
    def load_pipeline():
        if not os.path.exists(MODEL_PATH):
            with st.spinner("üì• T√©l√©chargement du mod√®le..."):
                r = requests.get(MODEL_URL)
                r.raise_for_status()
                with open(MODEL_PATH, "wb") as f:
                    f.write(r.content)
        return joblib.load(MODEL_PATH)

    pipe = load_pipeline()

    # =========================
    # Chargement du mapping
    # =========================
    BASE_DIR = os.path.dirname(__file__)
    mapping_path = os.path.join(BASE_DIR, "Y_train_encode.csv")

    mapping_df = pd.read_csv(mapping_path)
    mapping_df = mapping_df.drop_duplicates(subset=["prdtypecode_encoded"])

    mapping = mapping_df.set_index("prdtypecode_encoded")["libelle_type_code"].to_dict()

    # =========================
    # Pr√©diction
    # =========================
    if st.button("Valider"):
        if not designation_input.strip() and not description_input.strip():
            st.warning("Veuillez saisir au moins la d√©signation ou la description.")
        else:
        # Cr√©ation d'un DataFrame 1 ligne pour respecter le format du pipeline
            input_df = pd.DataFrame([{
                "designation": designation_input,
                "description": description_input
            }])

        # Pr√©diction
            pred = pipe.predict(input_df)[0]
            label = mapping.get(pred)

            if label:
                st.success(f"üîπ Cat√©gorie pr√©dite : **{label}**")
            else:
                st.success("üîπ Cat√©gorie pr√©dite : Non disponible")
